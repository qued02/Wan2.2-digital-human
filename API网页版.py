# app.py
import os
import oss2                     # é˜¿é‡Œäº‘å¯¹è±¡å­˜å‚¨
import sys
import uuid                     # ç”Ÿæˆå”¯ä¸€ID
import shutil                   # æ–‡ä»¶æ“ä½œ
import time                     # æ—¶é—´å¤„ç†ï¼Œç”¨äºè½®è¯¢ç­‰å¾…
import gradio as gr             # ç½‘é¡µç•Œé¢æ¡†æ¶ - æ ¸å¿ƒä¾èµ–2
import requests                 # HTTPè¯·æ±‚åº“ï¼Œç”¨äºè°ƒç”¨API - æ ¸å¿ƒä¾èµ–3

import dashscope                # é˜¿é‡Œäº‘AIæ¨¡å‹å¹³å°
from dashscope.utils.oss_utils import check_and_upload_local        # ä¸Šä¼ æ–‡ä»¶åˆ°OSSçš„å·¥å…·

DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")                  # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥ï¼Œè¿™æ˜¯è®¿é—®é˜¿é‡Œäº‘æœåŠ¡çš„"é€šè¡Œè¯"
dashscope.api_key = DASHSCOPE_API_KEY


class WanAnimateApp:
    def __init__(self, url, get_url):
        self.url = url                                     # ä»»åŠ¡æäº¤çš„APIåœ°å€
        self.get_url = get_url                             # ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢çš„APIåœ°å€

    def predict(                                           # ä¸Šä¼ åˆ°ossé˜¿é‡Œäº‘
        self, 
        ref_img,
        video,
        model_id,
        model,
    ):
        # Upload files to OSS if needed and get URLs
        _, image_url = check_and_upload_local(model_id, ref_img, DASHSCOPE_API_KEY)
        _, video_url = check_and_upload_local(model_id, video, DASHSCOPE_API_KEY)

        # Prepare the request payload           å‡†å¤‡è¯·æ±‚æ•°æ®
        payload = {
            "model": model_id,
            "input": {
                "image_url": image_url,
                "video_url": video_url
            },
            "parameters": {
                "check_image": True,
                "mode": model,
            }
        }
        
        # Set up headers                    è®¾ç½®httpè¯·æ±‚å¤´
        headers = {
            "X-DashScope-Async": "enable",                          # å¼‚æ­¥å¤„ç†
            "X-DashScope-OssResourceResolve": "enable",             # å…è®¸ossè¯»å–æ•°æ®   
            "Authorization": f"Bearer {DASHSCOPE_API_KEY}",         # èº«ä»½éªŒè¯
            "Content-Type": "application/json"                      # å‘é€jsonæ•°æ®
        }
        
        # Make the initial API request      
        url = self.url
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        
        # Check if request was successful
        if response.status_code != 200:
            raise Exception(f"Initial request failed with status code {response.status_code}: {response.text}")
        
        # Get the task ID from response     è·å–ä»»åŠ¡IDï¼Œé˜¿é‡Œç»™è¿™ä¸ªä»»åŠ¡çš„ID
        result = response.json()
        task_id = result.get("output", {}).get("task_id")
        if not task_id:
            raise Exception("Failed to get task ID from response")
        
        # Poll for results          è½®è¯¢ä»»åŠ¡çŠ¶æ€
        get_url = f"{self.get_url}/{task_id}"
        headers = {
            "Authorization": f"Bearer {DASHSCOPE_API_KEY}",
            "Content-Type": "application/json"
        }
        
        while True:             # æ— é™è½®è¯¢ï¼Œç›´åˆ°ä»»åŠ¡å®Œæˆæˆ–å¤±è´¥
            response = requests.get(get_url, headers=headers, timeout=60)
            if response.status_code != 200:
                raise Exception(f"Failed to get task status: {response.status_code}: {response.text}")
            
            result = response.json()
            print(result)
            task_status = result.get("output", {}).get("task_status")
            
            if task_status == "SUCCEEDED":
                # ä»»åŠ¡æˆåŠŸï¼Œè¿”å›è§†é¢‘URL
                video_url = result["output"]["results"]["video_url"]
                return video_url, "SUCCEEDED"
            elif task_status == "PENDING" or task_status == "RUNNING":
                #  ä»»åŠ¡è¿˜åœ¨è¿›è¡Œä¸­ï¼Œç­‰å¾…10ç§’å†æŸ¥è¯¢
                time.sleep(10)  
            else:
                # ä»»åŠ¡å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                error_msg = result.get("output", {}).get("message", "Unknown error")
                code_msg = result.get("output", {}).get("code", "Unknown code")
                print(f"\n\nTask failed: {error_msg} Code: {code_msg} TaskId: {task_id}\n\n")
                return None, f"Task failed: {error_msg} Code: {code_msg} TaskId: {task_id}"
                # raise Exception(f"Task failed: {error_msg} TaskId: {task_id}")

def start_app():
    import argparse
    parser = argparse.ArgumentParser(description="Wan2.2-Animate è§†é¢‘ç”Ÿæˆå·¥å…·")
    args = parser.parse_args()
    
    # APIåœ°å€
    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/image2video/video-synthesis/"

    get_url = f"https://dashscope.aliyuncs.com/api/v1/tasks/"

    app = WanAnimateApp(url=url, get_url=get_url)

    #åˆ›å»ºGradioç•Œé¢
    # +-----------------------------------------+
    # |         æ ‡é¢˜å’Œä»‹ç»HTML                   |
    # +-------------------+---------------------+
    # | è¾“å…¥åŒºåŸŸ          | è¾“å‡ºåŒºåŸŸ             |
    # | +--------------+  | +-----------------+ |
    # | | ä¸Šä¼ å›¾ç‰‡     |  | | æ˜¾ç¤ºç”Ÿæˆçš„è§†é¢‘  | |
    # | | ä¸Šä¼ è§†é¢‘     |  | | æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯    | |
    # | | é€‰æ‹©æ¨¡å¼     |  | +-----------------+ |
    # | | é€‰æ‹©è´¨é‡     |  |                     |
    # | | [ç”ŸæˆæŒ‰é’®]   |  |                     |
    # | +--------------+  |                     |
    # +-------------------+---------------------+
    
    with gr.Blocks(title="Wan2.2-Animate è§†é¢‘ç”Ÿæˆ") as demo:
        gr.HTML("""
            
            <div style="padding: 2rem; text-align: center; max-width: 1200px; margin: 0 auto; font-family: Arial, sans-serif;">
                <h1 style="font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem; color: #333;">
                    Wan2.2-Animate: Unified Character Animation and Replacement with Holistic Replication
                </h1>
                
                <h3 style="font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem; color: #333;">
                    Wan2.2-Animate: ç»Ÿä¸€çš„è§’è‰²åŠ¨ç”»å’Œè§†é¢‘äººç‰©æ›¿æ¢æ¨¡å‹
                </h3>
                <div style="font-size: 1.25rem; margin-bottom: 1.5rem; color: #555;">
                    Tongyi Lab, Alibaba
                </div>
                <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 1rem; margin-bottom: 1rem;">
                    <!-- ç¬¬ä¸€è¡ŒæŒ‰é’® -->
                    <a href="https://arxiv.org/abs/2509.14055" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; /* æµ…ç°è‰²èƒŒæ™¯ */ color: #333; /* æ·±è‰²æ–‡å­— */ text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ“„</span> <!-- ä½¿ç”¨æ–‡æ¡£å›¾æ ‡ -->
                        <span>Paper</span>
                    </a>
                    <a href="https://github.com/Wan-Video/Wan2.2" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ’»</span> <!-- ä½¿ç”¨ç”µè„‘å›¾æ ‡ -->
                        <span>GitHub</span>
                    </a>
                    <a href="https://huggingface.co/Wan-AI/Wan2.2-Animate-14B" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ¤—</span>
                        <span>HF Model</span>
                    </a>
                    <a href="https://www.modelscope.cn/models/Wan-AI/Wan2.2-Animate-14B" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ¤–</span>
                        <span>MS Model</span>
                    </a>
                </div>
                <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 1rem;">
                    <!-- ç¬¬äºŒè¡ŒæŒ‰é’® -->
                    <a href="https://huggingface.co/spaces/Wan-AI/Wan2.2-Animate" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ¤—</span>
                        <span>HF Space</span>
                    </a>
                    <a href="https://www.modelscope.cn/studios/Wan-AI/Wan2.2-Animate" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ¤–</span>
                        <span>MS Studio</span>
                    </a>
                </div>
            </div>
            
            """)
        
        gr.HTML("""
                <details>
                    <summary>â€¼ï¸Usage (ä½¿ç”¨è¯´æ˜)</summary>
                    
                    Wan-Animate supports two mode:
                    <ul>
                        <li>Move Mode: animate the  character in input image with movements from the input video</li>
                        <li>Mix Mode: replace the character in input video with the character in input image</li>
                    </ul>
                    
                    Wan-Animate æ”¯æŒä¸¤ç§æ¨¡å¼:
                    <ul>
                        <li>Moveæ¨¡å¼: ç”¨è¾“å…¥è§†é¢‘ä¸­æå–çš„åŠ¨ä½œï¼Œé©±åŠ¨è¾“å…¥å›¾ç‰‡ä¸­çš„è§’è‰²</li>
                        <li>Mixæ¨¡å¼: ç”¨è¾“å…¥å›¾ç‰‡ä¸­çš„è§’è‰²ï¼Œæ›¿æ¢è¾“å…¥è§†é¢‘ä¸­çš„è§’è‰²</li>
                    </ul>
                    Currently, the following restrictions apply to inputs:
                    <ul> <li>Video file size: Less than 200MB</li> 
                    <li>Video resolution: The shorter side must be greater than 200, and the longer side must be less than 2048</li> 
                    <li>Video duration: 2s to 30s</li> 
                    <li>Video aspect ratio: 1:3 to 3:1</li> 
                    <li>Video formats: mp4, avi, mov</li> 
                    <li>Image file size: Less than 5MB</li> 
                    <li>Image resolution: The shorter side must be greater than 200, and the longer side must be less than 4096</li> 
                    <li>Image formats: jpg, png, jpeg, webp, bmp</li> </ul>
                    
                    å½“å‰ï¼Œå¯¹äºè¾“å…¥æœ‰ä»¥ä¸‹çš„é™åˆ¶ 
                    <ul>
                        <li>è§†é¢‘æ–‡ä»¶å¤§å°: å°äº 200MB</li>
                        <li>è§†é¢‘åˆ†è¾¨ç‡ï¼š æœ€å°è¾¹å¤§äº 200, æœ€å¤§è¾¹å°äº2048</li>
                        <li>è§†é¢‘æ—¶é•¿: 2s ~ 30s </li> 
                        <li>è§†é¢‘æ¯”ä¾‹ï¼š1:3 ~ 3:1 </li>
                        <li>è§†é¢‘æ ¼å¼: mp4, avi, mov </li> 
                        <li>å›¾ç‰‡æ–‡ä»¶å¤§å°: å°äº5MB </li>
                        <li>å›¾ç‰‡åˆ†è¾¨ç‡ï¼šæœ€å°è¾¹å¤§äº200ï¼Œæœ€å¤§è¾¹å°äº4096 </li>
                        <li>å›¾ç‰‡æ ¼å¼: jpg, png, jpeg, webp, bmp </li> 
                    </ul>     
                    
                    <p> Currently, the inference quality has two variants. You can use our open-source code for more flexible configuration. </p>
                    
                    <p>å½“å‰ï¼Œæ¨ç†è´¨é‡æœ‰ä¸¤ä¸ªå˜ç§ã€‚ æ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„å¼€æºä»£ç ï¼Œæ¥è¿›è¡Œæ›´çµæ´»çš„è®¾ç½®ã€‚</p>
                    
                    <ul>
                        <li> wan-pro: 25fps, 720p </li> 
                        <li> wan-std: 15fps, 720p  </li>
                    </ul>     
                              
                </details>                
                """)

        with gr.Row():              # åˆ›å»ºè¾“å…¥çŸ©é˜µ
            with gr.Column():    
                ref_img = gr.Image(
                    label="Reference Image(å‚è€ƒå›¾åƒ)",
                    type="filepath",        # è¿”å›æ–‡ä»¶è·¯å¾„  
                    sources=["upload"],     #  åªå…è®¸ä¸Šä¼ æ–‡ä»¶
                )
                
                video = gr.Video(
                    label="Template Video(æ¨¡ç‰ˆè§†é¢‘)",
                    sources=["upload"],     #  åªå…è®¸ä¸Šä¼ æ–‡ä»¶
                )
                
                with gr.Row():
                    model_id = gr.Dropdown(
                        label="Mode(æ¨¡å¼)",
                        choices=["wan2.2-animate-move", "wan2.2-animate-mix"],
                        value="wan2.2-animate-move",    # é»˜è®¤å€¼
                        info=""
                    )

                    model = gr.Dropdown(
                        label="æ¨ç†è´¨é‡(Inference Quality)",
                        choices=["wan-pro", "wan-std"],
                        value="wan-pro",
                    )

                run_button = gr.Button("Generate Video(ç”Ÿæˆè§†é¢‘)")

            with gr.Column():                   # åˆ›å»ºè¾“å‡ºçŸ©é˜µ
                output_video = gr.Video(label="Output Video(è¾“å‡ºè§†é¢‘)")
                output_status = gr.Textbox(label="Status(çŠ¶æ€)")
        
        run_button.click(                       # ç»‘å®šæŒ‰é’®ç‚¹å‡»äº‹ä»¶
            fn=app.predict,                     # ç‚¹å‡»æ—¶è°ƒç”¨çš„å‡½æ•°
            inputs=[                            # è¾“å…¥å‚æ•°
                ref_img,
                video,
                model_id,
                model,
            ],
            outputs=[output_video, output_status],      #è¾“å‡ºç»“æœ
        )

        example_data = [
            ['./examples/mov/1/1.jpeg', './examples/mov/1/1.mp4', 'wan2.2-animate-move', 'wan-pro'],
            ['./examples/mov/2/2.jpeg', './examples/mov/2/2.mp4', 'wan2.2-animate-move', 'wan-pro'],
            ['./examples/mix/1/1.jpeg', './examples/mix/1/1.mp4', 'wan2.2-animate-mix', 'wan-pro'],
            ['./examples/mix/2/2.jpeg', './examples/mix/2/2.mp4', 'wan2.2-animate-mix', 'wan-pro']
        ]

        if example_data:
            gr.Examples(
                examples=example_data,
                inputs=[ref_img, video, model_id, model],
                outputs=[output_video, output_status],
                fn=app.predict,
                cache_examples="lazy",
            )
    
    demo.queue(default_concurrency_limit=100)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860
    )


if __name__ == "__main__":
    start_app()